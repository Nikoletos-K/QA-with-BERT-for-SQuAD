{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_SQUAD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2fde71f6d41644849e4ebe6a5acadd29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aecd5661d29942239bd6016b5d45c5ac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ced0fe54bc054408a3dd846920e10eda",
              "IPY_MODEL_34e1fafe77f04c528932c4a280fb9447"
            ]
          }
        },
        "aecd5661d29942239bd6016b5d45c5ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ced0fe54bc054408a3dd846920e10eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a9f06a0e24f54a78bc3e9aea0df6e26d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4c33ec51dd845bda74b38466cb0ddb7"
          }
        },
        "34e1fafe77f04c528932c4a280fb9447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_540feeb5bcf947c5924391d94f5f0bdb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 632kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_802396ff22b3428ab8548fa14665ff11"
          }
        },
        "a9f06a0e24f54a78bc3e9aea0df6e26d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4c33ec51dd845bda74b38466cb0ddb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "540feeb5bcf947c5924391d94f5f0bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "802396ff22b3428ab8548fa14665ff11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b96c973c4d6b4462bf15d1484c06e0f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ae3daf02251451281fbfeb403d87e39",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cd2a97f2a32c4d0cb08cec1dab02cd60",
              "IPY_MODEL_ca3eb1ac0e674b9aa677e212f726d810"
            ]
          }
        },
        "4ae3daf02251451281fbfeb403d87e39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd2a97f2a32c4d0cb08cec1dab02cd60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ad67fb84fd574ca88f2a70fc98956fbc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16d9052f9c5a49e7a1aba58f9740da43"
          }
        },
        "ca3eb1ac0e674b9aa677e212f726d810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c5a9f553a6b4ae6babb96c2e8a23b73",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:10&lt;00:00, 41.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc098faa1e6845d889c50cb29529a15e"
          }
        },
        "ad67fb84fd574ca88f2a70fc98956fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16d9052f9c5a49e7a1aba58f9740da43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c5a9f553a6b4ae6babb96c2e8a23b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc098faa1e6845d889c50cb29529a15e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93d144a0d3da44748350fd94dc763157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fe4903de421348d9a589bd7006df439b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b28483a2ca33451ab61a1b89255a3f1f",
              "IPY_MODEL_639e5327bd3b48e8b12566acab001bd8"
            ]
          }
        },
        "fe4903de421348d9a589bd7006df439b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b28483a2ca33451ab61a1b89255a3f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_115f8508367143e1a7b8e05ecf835b16",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_514c96db6a114a24867351e4d507643f"
          }
        },
        "639e5327bd3b48e8b12566acab001bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_18753fbe3c6542a5b2371f7e3991b3a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 45.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12998d3de6104ce8b2018e02bb808a59"
          }
        },
        "115f8508367143e1a7b8e05ecf835b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "514c96db6a114a24867351e4d507643f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18753fbe3c6542a5b2371f7e3991b3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12998d3de6104ce8b2018e02bb808a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T28QEDT-Uqj2"
      },
      "source": [
        "<p align=\"center\">\n",
        " <img src=\"http://www.di.uoa.gr/themes/corporate_lite/logo_el.png\" title=\"Department of Informatics and Telecommunications - University of Athens\"/> </p>\n",
        "\n",
        "---\n",
        "<h1 align=\"center\" style=\"font-style: italic;\"> \n",
        "  Artificial Intelligence II\n",
        "</h1>\n",
        "<h1 align=\"center\" > \n",
        "  Deep Learning for Natural Language Processing\n",
        "</h1>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<h3 align=\"center\"> \n",
        " <b>Winter semester 2020-2021</b>\n",
        "</h3>\n",
        "<h3 align=\"center\"> \n",
        " <b>Konstantinos Nikoletos</b>\n",
        "</h3>\n",
        "<h3 align=\"center\"> \n",
        " <b>sdi: 1115201700104</b>\n",
        "</h3>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk9SOEk6mCXZ"
      },
      "source": [
        "---\n",
        "---\n",
        "#  <center> <b>  </b> </center>\n",
        "\n",
        "### __Task__ \n",
        "Build a BERT-based model which returns “an answer”, given a user question and a\n",
        "passage which includes the answer of the question. For this question answering task, you\n",
        "will use the SQuAD 2.0 dataset which has been discussed in the lecture “Textual Question\n",
        "Answering”. You should start with the BERT-base pretrained model “bert-base-uncased”\n",
        "and fine-tune it to have a question answering task as explained in the lecture on BERT.\n",
        "Note that this has been done already by the BERT team and it is available publicly, but\n",
        "we would like you to try to implement this by yourself. If you copy from the BERT code\n",
        "for this task, your mark for this exercise will be 0.\n",
        "For more information about question answering systems, you can read the post “How to\n",
        "Build an Open-Domain Question Answering System?” and the survey “Recent Trends in\n",
        "Deep Learning Based Open-Domain Textual Question Answering Systems”.\n",
        "\n",
        "### __Notebook__ \n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OfAccyufasd"
      },
      "source": [
        "__Import__ of essential libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVSHtKTrfGiV",
        "outputId": "9d94b80f-b10c-4b90-ad20-cd6a591ff91c"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "import sys # only needed to determine Python version number\n",
        "import matplotlib # only needed to determine Matplotlib version \n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import pprint\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext import data\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import logging\n",
        "from tqdm import tqdm, trange\n",
        "import re\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s2pt_N5zrQL",
        "outputId": "dfe70282-090f-4ebd-c776-bdb4dcb56570"
      },
      "source": [
        "!pip install colorama"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U71ODzhgzpDt"
      },
      "source": [
        "import colorama\r\n",
        "from colorama import Fore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC9DWskzConr"
      },
      "source": [
        "Selecting device (GPU - CUDA if available)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiRkpLhiCntl",
        "outputId": "9f9f72e4-65e0-4142-d551-5aae2a4aa31d"
      },
      "source": [
        "# First checking if GPU is available\r\n",
        "train_on_gpu=torch.cuda.is_available()\r\n",
        "\r\n",
        "if(train_on_gpu):\r\n",
        "    print('Training on GPU.')\r\n",
        "    torch.cuda.empty_cache()\r\n",
        "else:\r\n",
        "    print('No GPU available, training on CPU.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aikt1C0Sh3m3",
        "outputId": "2605310a-a6c1-4be4-ee9b-2bd5a73aca9b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 10.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 34.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 27.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=0a07ed7bfc59dcbf698849ee391dbb724662aafb6d674e44ff78a66858e1f480\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbY9lWarnOI9"
      },
      "source": [
        "from tokenizers import BertWordPieceTokenizer\r\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvK_TWa2YNg5"
      },
      "source": [
        "# Loading data\r\n",
        "---\r\n",
        "\r\n",
        "## SQuAD Dataset\r\n",
        "Stanford Question Answering Dataset (SQuAD) is a new reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage. With 100,000+ question-answer pairs on 500+ articles, SQuAD is significantly larger than previous reading comprehension datasets.\r\n",
        "\r\n",
        "## Problem\r\n",
        "For each observation in the training set, we have a context, question, and text.\r\n",
        "The goal is to find the text for any new question and context provided. This is a closed dataset meaning that the answer to a question is always a part of the context and also a continuous span of context. \r\n",
        "- Getting the sentence having the right answer\r\n",
        "- Once the sentence is finalized, getting the correct answer from the sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mvb-AkOlkDZv",
        "outputId": "500a0acd-5584-46cc-862f-dc91bfd5dac5"
      },
      "source": [
        "# Opening data file\r\n",
        "import io\r\n",
        "import os\r\n",
        "from google.colab import drive\r\n",
        "from os import listdir\r\n",
        "from os.path import isfile, join\r\n",
        "import json\r\n",
        "import sys\r\n",
        "\r\n",
        "drive.mount('/content/drive/',force_remount=True)\r\n",
        "%cd drive/My\\ Drive/AI_4\r\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/AI_4\n",
            "/content/drive/My Drive/AI_4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eWB65lSkz5G"
      },
      "source": [
        "Loading SQuAD 2.0 dataset training and validation set\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjYwmTVOYMlY"
      },
      "source": [
        "train_path = r'train-v2.0.json'\r\n",
        "train_data = open(train_path, 'rb')\r\n",
        "raw_train_data = json.load(train_data)\r\n",
        "\r\n",
        "eval_path = r'dev-v2.0.json'\r\n",
        "eval_data = open(eval_path, 'rb')\r\n",
        "raw_eval_data = json.load(eval_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mby3LqSqm2eV"
      },
      "source": [
        "2 tokenizers:\r\n",
        "\r\n",
        "- BertWordPieceTokenizer\r\n",
        "- BertTokenizer\r\n",
        "\r\n",
        "Same encoding, but BertWordPieceTokenizer is faster than BertTokenizer as it is implemented in Rust"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "2fde71f6d41644849e4ebe6a5acadd29",
            "aecd5661d29942239bd6016b5d45c5ac",
            "ced0fe54bc054408a3dd846920e10eda",
            "34e1fafe77f04c528932c4a280fb9447",
            "a9f06a0e24f54a78bc3e9aea0df6e26d",
            "e4c33ec51dd845bda74b38466cb0ddb7",
            "540feeb5bcf947c5924391d94f5f0bdb",
            "802396ff22b3428ab8548fa14665ff11"
          ]
        },
        "id": "CuWGSyY4mcX9",
        "outputId": "116ceb1d-dc39-4510-e543-2416cd6443fe"
      },
      "source": [
        "!mkdir \"bert_base_uncased\"\r\n",
        "\r\n",
        "slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\r\n",
        "slow_tokenizer.save_pretrained(\"bert_base_uncased/\")\r\n",
        "\r\n",
        "fast_tokenizer = BertWordPieceTokenizer(\"bert_base_uncased/vocab.txt\", lowercase=True)\r\n",
        "tokenizer = fast_tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘bert_base_uncased’: File exists\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fde71f6d41644849e4ebe6a5acadd29",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZRX989wSvCt"
      },
      "source": [
        "Two dataframes for a better represantation of the training and validation set SQuAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYfFZBa-2JXV"
      },
      "source": [
        "squadDf = pd.DataFrame()\r\n",
        "val_squadDf = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oif_33Seouy3"
      },
      "source": [
        "# Pre-process\r\n",
        "---\r\n",
        "Preparing dataset SQuAD 2.0. I am going to create and use a class with all the needed functions in order to read json and process it.\r\n",
        "\r\n",
        "Variables that I am going to read and store:\r\n",
        "\r\n",
        "- questions (id and text)\r\n",
        "- paragraphs that have the answers\r\n",
        "- token start and end of each answer\r\n",
        "- answers as text\r\n",
        "\r\n",
        "After reading the json file, I am going:\r\n",
        "\r\n",
        "1. Find the end token of each answer\r\n",
        "2. Create the array of ints that BERT needs\r\n",
        "3. Encode the data\r\n",
        "4. Insert the mask\r\n",
        "5. Make the padding\r\n",
        "\r\n",
        "> Because BERT is a pretrained model that expects input data in a specific format, we will need:\r\n",
        "1. A **special token, `[SEP]`,** to mark the end of a sentence, or the separation between two sentences\r\n",
        "2. A **special token, `[CLS]`,** at the beginning of our text. This token is used for classification tasks, but BERT expects it no matter what your application is. \r\n",
        "3. Tokens that conform with the fixed vocabulary used in BERT\r\n",
        "4. The **Token IDs** for the tokens, from BERT's tokenizer\r\n",
        "5. **Mask IDs** to indicate which elements in the sequence are tokens and which are padding elements\r\n",
        "6. **Segment IDs** used to distinguish different sentences\r\n",
        "7. **Positional Embeddings** used to show token position within the sequence\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "All these will be implemented as one class ```SQuAD_Dataset``` that has the preprocess function implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN14BnP-ouW4"
      },
      "source": [
        "class SQuAD_Dataset:\r\n",
        "    '''\r\n",
        "    Constructor: all fields in the json file\r\n",
        "    '''\r\n",
        "    def __init__(self, question, context, start_char_idx=None, answer_text=None, all_answers=None):\r\n",
        "        self.question = question\r\n",
        "        self.context = context\r\n",
        "        self.start_char_idx = start_char_idx\r\n",
        "        self.end_char_idx = -1\r\n",
        "        self.answer_text = answer_text\r\n",
        "        self.all_answers = all_answers\r\n",
        "        self.skip = False\r\n",
        "        self.start_token_idx = -1\r\n",
        "        self.end_token_idx = -1\r\n",
        "        \r\n",
        "\r\n",
        "    '''\r\n",
        "    Pre-process: tokenizing and encoding paragraphs and questions, as BERT encoding needs\r\n",
        "    '''\r\n",
        "    def preprocess(self):\r\n",
        "\r\n",
        "        # Isolating context and questions from the given json\r\n",
        "        context = \" \".join(str(self.context).split())\r\n",
        "        question = \" \".join(str(self.question).split())\r\n",
        "\r\n",
        "        # Text encoding\r\n",
        "        tokenized_context = tokenizer.encode(context)\r\n",
        "        tokenized_question = tokenizer.encode(question)\r\n",
        "\r\n",
        "        # Marking start and end of answers in text\r\n",
        "        if self.answer_text is not None:\r\n",
        "            answer = \" \".join(str(self.answer_text).split())\r\n",
        "\r\n",
        "            # Finding last token of the answer\r\n",
        "            end_char_idx = self.start_char_idx + len(answer)\r\n",
        "            \r\n",
        "            # If end before start skip\r\n",
        "            if end_char_idx >= len(context):\r\n",
        "                self.skip = True\r\n",
        "                return\r\n",
        "            \r\n",
        "            self.end_char_idx = end_char_idx\r\n",
        "\r\n",
        "            # Creating the array of 0s and 1s as BERT needs\r\n",
        "            is_char_in_ans = [0] * len(context)\r\n",
        "            for idx in range(self.start_char_idx, end_char_idx):\r\n",
        "                is_char_in_ans[idx] = 1\r\n",
        "\r\n",
        "            # Finding answers token\r\n",
        "            ans_token_idx = []\r\n",
        "            for idx, (start, end) in enumerate(tokenized_context.offsets):\r\n",
        "                if sum(is_char_in_ans[start:end]) > 0:\r\n",
        "                    ans_token_idx.append(idx)\r\n",
        "            if len(ans_token_idx) == 0:\r\n",
        "                self.skip = True\r\n",
        "                return\r\n",
        "            \r\n",
        "            # Initializing class attributes\r\n",
        "            self.start_token_idx = ans_token_idx[0]\r\n",
        "            self.end_token_idx = ans_token_idx[-1]\r\n",
        "        \r\n",
        "        #  Converted ids from encoding\r\n",
        "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\r\n",
        "\r\n",
        "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(tokenized_question.ids[1:])\r\n",
        "\r\n",
        "        # Creating the mask\r\n",
        "        attention_mask = [1] * len(input_ids)\r\n",
        "\r\n",
        "        # Creating the Padding\r\n",
        "        padding_length = max_seq_length - len(input_ids)\r\n",
        "\r\n",
        "        if padding_length > 0:\r\n",
        "            input_ids = input_ids + ([0] * padding_length)\r\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\r\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)\r\n",
        "        elif padding_length < 0:\r\n",
        "            self.skip = True\r\n",
        "            return\r\n",
        "\r\n",
        "        # Initializing class variables \r\n",
        "        self.input_word_ids = input_ids\r\n",
        "        self.input_type_ids = token_type_ids\r\n",
        "        self.input_mask = attention_mask\r\n",
        "        self.context_token_to_char = tokenized_context.offsets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obnxFDW8UWyk"
      },
      "source": [
        "# Spliting and preparing datasets for training and validation\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BOCuVn0zKo5"
      },
      "source": [
        "'''\r\n",
        "Creating squad: Creating the SQuAD dataset QAs, returns the preprocessed dataset that consists of vectors to be train. Also I've inserted a dataframe for visualizing the data \r\n",
        "'''\r\n",
        "def create_squad(raw_data, desc, df):\r\n",
        "\r\n",
        "    if len(desc)!=0:\r\n",
        "      p_bar = tqdm(total=len(raw_data[\"data\"]), desc=desc,position=0, leave=True,file=sys.stdout, bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % (Fore.BLUE, Fore.RESET))\r\n",
        "    \r\n",
        "    squad_examples = []\r\n",
        "\r\n",
        "    # Dataframe variables initilization\r\n",
        "    if isinstance(df, pd.DataFrame):\r\n",
        "      titles = []\r\n",
        "      ids = []\r\n",
        "      contents = []\r\n",
        "      answer_start = []\r\n",
        "      answer_end = []\r\n",
        "      answers = []\r\n",
        "      imp = []\r\n",
        "      allans = []\r\n",
        "      questions = []\r\n",
        "      skip = []\r\n",
        "    \r\n",
        "    # -------- Processing json data ---------\r\n",
        "    for item in raw_data[\"data\"]:\r\n",
        "      title = item[\"title\"]\r\n",
        "      for para in item[\"paragraphs\"]:            \r\n",
        "        context = para[\"context\"]\r\n",
        "        for qa in para[\"qas\"]:\r\n",
        "          question = qa[\"question\"]\r\n",
        "          is_impossible = qa[\"is_impossible\"]\r\n",
        "          id = qa[\"id\"]\r\n",
        "\r\n",
        "          if (\"answers\" in qa) or (\"plausible_answers\" in qa):\r\n",
        "            if len(qa[\"answers\"]):\r\n",
        "              answer_text = qa[\"answers\"][0][\"text\"]\r\n",
        "              all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\r\n",
        "              start_char_idx = qa[\"answers\"][0][\"answer_start\"]    \r\n",
        "              \r\n",
        "            if \"plausible_answers\" in qa and len(qa[\"plausible_answers\"]):\r\n",
        "              answer_text += qa[\"plausible_answers\"][0][\"text\"]\r\n",
        "              all_answers += [_[\"text\"] for _ in qa[\"plausible_answers\"]]\r\n",
        "              start_char_idx += qa[\"plausible_answers\"][0][\"answer_start\"]\r\n",
        "\r\n",
        "            # Creating set\r\n",
        "            squad = SQuAD_Dataset(question, context, start_char_idx, answer_text, all_answers)  \r\n",
        "\r\n",
        "            if isinstance(df, pd.DataFrame):\r\n",
        "              # Initializing variables for the dataframe\r\n",
        "              questions.append(question)\r\n",
        "              answers.append(answer_text)\r\n",
        "              answer_start.append(start_char_idx)\r\n",
        "              titles.append(title)\r\n",
        "              imp.append(is_impossible)\r\n",
        "              ids.append(id)\r\n",
        "              contents.append(context)\r\n",
        "              allans.append(all_answers)\r\n",
        "\r\n",
        "          else:\r\n",
        "            squad = SQuAD_Dataset(question, context)\r\n",
        "          \r\n",
        "\r\n",
        "          squad.preprocess()\r\n",
        "          if isinstance(df, pd.DataFrame):\r\n",
        "            answer_end.append(squad.end_char_idx)\r\n",
        "            skip.append(squad.skip)\r\n",
        "          \r\n",
        "          squad_examples.append(squad)\r\n",
        "\r\n",
        "      if len(desc)!=0:\r\n",
        "        p_bar.update(1)\r\n",
        "\r\n",
        "    if len(desc)!=0:   \r\n",
        "      p_bar.close()\r\n",
        "    \r\n",
        "    if isinstance(df, pd.DataFrame):\r\n",
        "      df['question_id'] = ids\r\n",
        "      df['title'] = titles\r\n",
        "      df['question'] = questions\r\n",
        "      df['context'] = context\r\n",
        "      df['answer'] = answers\r\n",
        "      df['all_answers'] = answers\r\n",
        "      df['answer_start'] = answer_start\r\n",
        "      df['answer_end'] = answer_end\r\n",
        "      df['is_impossible'] = imp\r\n",
        "      df['skip'] = skip\r\n",
        "\r\n",
        "\r\n",
        "    return squad_examples\r\n",
        "\r\n",
        "'''\r\n",
        "Xy_split: Splitting the dataset to the previous masked encodings as the X and the starting and ending token as the true label y. \r\n",
        "          Returning a dictionary of [input_word_ids,input_mask,input_type_ids],[start_token_idx,end_token_idx] as BERT needs.\r\n",
        "'''\r\n",
        "def Xy_split(squad_examples):\r\n",
        "    dataset_dict = {\r\n",
        "        \"input_word_ids\": [],\r\n",
        "        \"input_type_ids\": [],\r\n",
        "        \"input_mask\": [],\r\n",
        "        \"start_token_idx\": [],\r\n",
        "        \"end_token_idx\": [],\r\n",
        "    }\r\n",
        "\r\n",
        "    for item in squad_examples:\r\n",
        "        # Do not insert data with mixed start and end answers tokens -> skip them\r\n",
        "        if item.skip is False:\r\n",
        "            for key in dataset_dict:\r\n",
        "                dataset_dict[key].append(getattr(item, key))\r\n",
        "\r\n",
        "    # dataset_dict is a dictionary that stores every format of the data BERT needs (word ids,types and masked data)\r\n",
        "    for key in dataset_dict:\r\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\r\n",
        "    \r\n",
        "    x = [dataset_dict[\"input_word_ids\"], dataset_dict[\"input_mask\"], dataset_dict[\"input_type_ids\"]]\r\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\r\n",
        "\r\n",
        "    return x, y\r\n",
        "\r\n",
        "\r\n",
        "'''\r\n",
        "Text normalization: Lower, no pancutation, unicode format and this function is used\r\n",
        "                    for comaring predicted answer with the true ansers in order to find accuracy and hence evaluate model\r\n",
        "'''\r\n",
        "def normalize_text(text):\r\n",
        "    text = text.lower() # no capitals\r\n",
        "    text = \"\".join(ch for ch in text if ch not in set(string.punctuation)) # no pancutation\r\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE) # no a,an,the to sentences\r\n",
        "    text = re.sub(regex, \" \", text) \r\n",
        "    text = \" \".join(text.split())\r\n",
        "\r\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEu5mw5OyjGK"
      },
      "source": [
        "Forming tensors from the initial set\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-fkgQr3yrIG",
        "outputId": "ba585232-1b4c-4290-acf1-35f74fe602cf"
      },
      "source": [
        "max_seq_length = 256  # bigger seq lengths crashed CUDA\r\n",
        "\r\n",
        "train_squad_examples = create_squad(raw_train_data, \"Creating training data   \",squadDf)\r\n",
        "X_train, y_train = Xy_split(train_squad_examples)\r\n",
        "\r\n",
        "eval_squad_examples = create_squad(raw_eval_data,   \"Creating validation data \",val_squadDf)\r\n",
        "X_eval, y_eval = Xy_split(eval_squad_examples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating training data   : 100%|\u001b[34m██████████\u001b[39m| 442/442 [01:26<00:00,  5.12it/s]\n",
            "Creating validation data : 100%|\u001b[34m██████████\u001b[39m| 35/35 [00:07<00:00,  4.49it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecvZHtIpdtYM"
      },
      "source": [
        "# Visualizing data\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "J1u-rsPzOVOM",
        "outputId": "b140d74c-86bc-400e-fea8-dcb1f5578267"
      },
      "source": [
        "squadDf.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>title</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>answer</th>\n",
              "      <th>all_answers</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer_end</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>skip</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>269</td>\n",
              "      <td>286</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>207</td>\n",
              "      <td>226</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56be85543aeaaa14008c9066</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>526</td>\n",
              "      <td>530</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Houston, Texas</td>\n",
              "      <td>Houston, Texas</td>\n",
              "      <td>166</td>\n",
              "      <td>180</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>276</td>\n",
              "      <td>286</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9603</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>In what R&amp;B group was she the lead singer?</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Destiny's Child</td>\n",
              "      <td>Destiny's Child</td>\n",
              "      <td>320</td>\n",
              "      <td>335</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9604</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>What album made her a worldwide known artist?</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Dangerously in Love</td>\n",
              "      <td>Dangerously in Love</td>\n",
              "      <td>505</td>\n",
              "      <td>524</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9605</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Who managed the Destiny's Child group?</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>Mathew Knowles</td>\n",
              "      <td>Mathew Knowles</td>\n",
              "      <td>360</td>\n",
              "      <td>374</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>56d43c5f2ccc5a1400d830a9</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>When did Beyoncé rise to fame?</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>276</td>\n",
              "      <td>286</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>56d43c5f2ccc5a1400d830aa</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>What role did Beyoncé have in Destiny's Child?</td>\n",
              "      <td>The term \"matter\" is used throughout physics i...</td>\n",
              "      <td>lead singer</td>\n",
              "      <td>lead singer</td>\n",
              "      <td>290</td>\n",
              "      <td>301</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                question_id    title  ... is_impossible   skip\n",
              "0  56be85543aeaaa14008c9063  Beyoncé  ...         False  False\n",
              "1  56be85543aeaaa14008c9065  Beyoncé  ...         False  False\n",
              "2  56be85543aeaaa14008c9066  Beyoncé  ...         False  False\n",
              "3  56bf6b0f3aeaaa14008c9601  Beyoncé  ...         False  False\n",
              "4  56bf6b0f3aeaaa14008c9602  Beyoncé  ...         False  False\n",
              "5  56bf6b0f3aeaaa14008c9603  Beyoncé  ...         False  False\n",
              "6  56bf6b0f3aeaaa14008c9604  Beyoncé  ...         False  False\n",
              "7  56bf6b0f3aeaaa14008c9605  Beyoncé  ...         False  False\n",
              "8  56d43c5f2ccc5a1400d830a9  Beyoncé  ...         False  False\n",
              "9  56d43c5f2ccc5a1400d830aa  Beyoncé  ...         False  False\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "0ngXrZc_cOjf",
        "outputId": "d047565b-2f8b-4300-e6ed-aedbc87dbd12"
      },
      "source": [
        "val_squadDf.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>title</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>answer</th>\n",
              "      <th>all_answers</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer_end</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>skip</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56ddde6b9a695914005b9628</td>\n",
              "      <td>Normans</td>\n",
              "      <td>In what country is Normandy located?</td>\n",
              "      <td>The pound-force has a metric counterpart, less...</td>\n",
              "      <td>France</td>\n",
              "      <td>France</td>\n",
              "      <td>159</td>\n",
              "      <td>165</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56ddde6b9a695914005b9629</td>\n",
              "      <td>Normans</td>\n",
              "      <td>When were the Normans in Normandy?</td>\n",
              "      <td>The pound-force has a metric counterpart, less...</td>\n",
              "      <td>10th and 11th centuries</td>\n",
              "      <td>10th and 11th centuries</td>\n",
              "      <td>94</td>\n",
              "      <td>117</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56ddde6b9a695914005b962a</td>\n",
              "      <td>Normans</td>\n",
              "      <td>From which countries did the Norse originate?</td>\n",
              "      <td>The pound-force has a metric counterpart, less...</td>\n",
              "      <td>Denmark, Iceland and Norway</td>\n",
              "      <td>Denmark, Iceland and Norway</td>\n",
              "      <td>256</td>\n",
              "      <td>283</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56ddde6b9a695914005b962b</td>\n",
              "      <td>Normans</td>\n",
              "      <td>Who was the Norse leader?</td>\n",
              "      <td>The pound-force has a metric counterpart, less...</td>\n",
              "      <td>Rollo</td>\n",
              "      <td>Rollo</td>\n",
              "      <td>308</td>\n",
              "      <td>313</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56ddde6b9a695914005b962c</td>\n",
              "      <td>Normans</td>\n",
              "      <td>What century did the Normans first gain their ...</td>\n",
              "      <td>The pound-force has a metric counterpart, less...</td>\n",
              "      <td>10th century</td>\n",
              "      <td>10th century</td>\n",
              "      <td>671</td>\n",
              "      <td>683</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5ad39d53604f3c001a3fe8d1</td>\n",
              "      <td>Normans</td>\n",
              "      <td>Who gave their name to Normandy in the 1000's ...</td>\n",
              "      <td>The pound-force has a metric counterpart, less...</td>\n",
              "      <td>10th centuryNormans</td>\n",
              "      <td>10th centuryNormans</td>\n",
              "      <td>675</td>\n",
              "      <td>694</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5ad39d53604f3c001a3fe8d2</td>\n",
              "      <td>Normans</td>\n",
              "      <td>What is France a region of?</td>\n",
              "      <td>The pound-force has a metric counterpart, less...</td>\n",
              "      <td>10th centuryNormansNormandy</td>\n",
              "      <td>10th centuryNormansNormandy</td>\n",
              "      <td>812</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5ad39d53604f3c001a3fe8d3</td>\n",
              "      <td>Normans</td>\n",
              "      <td>Who did King Charles III swear fealty to?</td>\n",
              "      <td>The pound-force has a metric counterpart, less...</td>\n",
              "      <td>10th centuryNormansNormandyRollo</td>\n",
              "      <td>10th centuryNormansNormandyRollo</td>\n",
              "      <td>1120</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5ad39d53604f3c001a3fe8d4</td>\n",
              "      <td>Normans</td>\n",
              "      <td>When did the Frankish identity emerge?</td>\n",
              "      <td>The pound-force has a metric counterpart, less...</td>\n",
              "      <td>10th centuryNormansNormandyRollo10th century</td>\n",
              "      <td>10th centuryNormansNormandyRollo10th century</td>\n",
              "      <td>1791</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>56dddf4066d3e219004dad5f</td>\n",
              "      <td>Normans</td>\n",
              "      <td>Who was the duke in the battle of Hastings?</td>\n",
              "      <td>The pound-force has a metric counterpart, less...</td>\n",
              "      <td>William the Conqueror</td>\n",
              "      <td>William the Conqueror</td>\n",
              "      <td>1022</td>\n",
              "      <td>1043</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                question_id    title  ... is_impossible   skip\n",
              "0  56ddde6b9a695914005b9628  Normans  ...         False  False\n",
              "1  56ddde6b9a695914005b9629  Normans  ...         False  False\n",
              "2  56ddde6b9a695914005b962a  Normans  ...         False  False\n",
              "3  56ddde6b9a695914005b962b  Normans  ...         False  False\n",
              "4  56ddde6b9a695914005b962c  Normans  ...         False  False\n",
              "5  5ad39d53604f3c001a3fe8d1  Normans  ...          True  False\n",
              "6  5ad39d53604f3c001a3fe8d2  Normans  ...          True   True\n",
              "7  5ad39d53604f3c001a3fe8d3  Normans  ...          True   True\n",
              "8  5ad39d53604f3c001a3fe8d4  Normans  ...          True   True\n",
              "9  56dddf4066d3e219004dad5f  Normans  ...         False   True\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO3HPHEsdysK"
      },
      "source": [
        "# Transforming dataset to tensors and creating shuffled batches\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJPzyOXBy9q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dcf34f7-37a7-424c-ceea-f382ecb1165c"
      },
      "source": [
        "batch_size = 16\r\n",
        "\r\n",
        "# Training set transformation\r\n",
        "train_data = TensorDataset(torch.tensor(X_train[0], dtype=torch.int64),\r\n",
        "                           torch.tensor(X_train[1], dtype=torch.float),\r\n",
        "                           torch.tensor(X_train[2], dtype=torch.int64),\r\n",
        "                           torch.tensor(y_train[0], dtype=torch.int64),\r\n",
        "                           torch.tensor(y_train[1], dtype=torch.int64))\r\n",
        "print(f\"{len(train_data)} training points created.\")\r\n",
        "train_sampler = RandomSampler(train_data) # Randomizing data\r\n",
        "train_data_loader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size,drop_last=True)\r\n",
        "\r\n",
        "# Validation set transformation\r\n",
        "eval_data = TensorDataset(torch.tensor(X_eval[0], dtype=torch.int64),\r\n",
        "                          torch.tensor(X_eval[1], dtype=torch.float),\r\n",
        "                          torch.tensor(X_eval[2], dtype=torch.int64),\r\n",
        "                          torch.tensor(y_eval[0], dtype=torch.int64),\r\n",
        "                          torch.tensor(y_eval[1], dtype=torch.int64))\r\n",
        "print(f\"{len(eval_data)} evaluation points created.\")\r\n",
        "eval_sampler = SequentialSampler(eval_data)\r\n",
        "validation_data_loader = DataLoader(eval_data, sampler=eval_sampler, batch_size=batch_size,drop_last=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85014 training points created.\n",
            "6164 evaluation points created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU_BduifeIfd"
      },
      "source": [
        "## Selecting again GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfGQKq2LN_9f",
        "outputId": "868520ed-f704-4a0d-d6ff-38e3a6d1e13c"
      },
      "source": [
        "if train_on_gpu:\r\n",
        "  gpu = torch.device('cuda')\r\n",
        "  print(\"CUDA\")\r\n",
        "else:\r\n",
        "  gpu = torch.device('cpu')\r\n",
        "  print(\"CPU\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3VFIpNeeOb8"
      },
      "source": [
        "# Initializing BERT model and fine tunning the hyperparameters\r\n",
        "---\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "b96c973c4d6b4462bf15d1484c06e0f3",
            "4ae3daf02251451281fbfeb403d87e39",
            "cd2a97f2a32c4d0cb08cec1dab02cd60",
            "ca3eb1ac0e674b9aa677e212f726d810",
            "ad67fb84fd574ca88f2a70fc98956fbc",
            "16d9052f9c5a49e7a1aba58f9740da43",
            "6c5a9f553a6b4ae6babb96c2e8a23b73",
            "dc098faa1e6845d889c50cb29529a15e",
            "93d144a0d3da44748350fd94dc763157",
            "fe4903de421348d9a589bd7006df439b",
            "b28483a2ca33451ab61a1b89255a3f1f",
            "639e5327bd3b48e8b12566acab001bd8",
            "115f8508367143e1a7b8e05ecf835b16",
            "514c96db6a114a24867351e4d507643f",
            "18753fbe3c6542a5b2371f7e3991b3a2",
            "12998d3de6104ce8b2018e02bb808a59"
          ]
        },
        "id": "vvotykGVRzB6",
        "outputId": "caa9efb2-e2e2-4122-b84c-ae852cc3ce22"
      },
      "source": [
        "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\r\n",
        "\r\n",
        "if train_on_gpu:\r\n",
        "  model = model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b96c973c4d6b4462bf15d1484c06e0f3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93d144a0d3da44748350fd94dc763157",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpI-BMHXeZGr"
      },
      "source": [
        "## Initializing optimizer - Adam\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c55TkPRoR2G3"
      },
      "source": [
        "# Optimizer parameters\r\n",
        "param_optimizer = list(model.named_parameters())\r\n",
        "no_decay = ['bias', 'gamma', 'beta']\r\n",
        "optimizer_grouped_parameters = [\r\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\r\n",
        "     'weight_decay_rate': 0.01},\r\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\r\n",
        "     'weight_decay_rate': 0.0}\r\n",
        "]\r\n",
        "optimizer = torch.optim.Adam(lr=1e-5, betas=(0.9, 0.98), eps=1e-9, params=optimizer_grouped_parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu2AVNWSeknv"
      },
      "source": [
        "## Selecting numer of epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8n9r57rQg9m"
      },
      "source": [
        "epochs = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxZcMUTFe6Na"
      },
      "source": [
        "# Training and Validation\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxKxvryLN0Bu",
        "outputId": "01b20554-8670-4200-89b7-5cc9d5221f88"
      },
      "source": [
        "for epoch in range(1, epochs + 1):\r\n",
        "\r\n",
        "    # ----------------------- TRAINING -----------------------\r\n",
        "    \r\n",
        "    training_pbar = tqdm(total=len(train_data), position=0, leave=True, file=sys.stdout, bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % (Fore.GREEN, Fore.RESET))\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "\r\n",
        "    tr_loss = 0\r\n",
        "    training_steps = 0\r\n",
        "\r\n",
        "    # Loop for every batch\r\n",
        "    for step, batch in enumerate(train_data_loader):\r\n",
        "\r\n",
        "      # Every batch consists of the tuple that I transformed before\r\n",
        "      # I am sending to GPU every batch, because of memory consumption. This way model don't crashes because of limited memory\r\n",
        "      batch = tuple(t.to(gpu) for t in batch)\r\n",
        "\r\n",
        "      # Isolating data from the tuple\r\n",
        "      input_word_ids, input_mask, input_type_ids, start_token_idx, end_token_idx = batch\r\n",
        "      \r\n",
        "      # init Adam\r\n",
        "      optimizer.zero_grad()\r\n",
        "\r\n",
        "      # model train\r\n",
        "      loss, _, _ = model(input_ids=input_word_ids, attention_mask=input_mask, token_type_ids=input_type_ids, start_positions=start_token_idx,end_positions=end_token_idx, return_dict=False)\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()\r\n",
        "\r\n",
        "      # Summing loss\r\n",
        "      tr_loss += loss.item()\r\n",
        "      training_steps += 1\r\n",
        "\r\n",
        "      # progress bar\r\n",
        "      training_pbar.update(input_word_ids.size(0))\r\n",
        "    \r\n",
        "    training_pbar.close()\r\n",
        "\r\n",
        "    # Average training loss\r\n",
        "    training_loss = tr_loss / training_steps\r\n",
        "    \r\n",
        "    \r\n",
        "    # Saving model (in each epoch) for future runs\r\n",
        "    torch.save(model.state_dict(), \"./weights_\" + str(epoch) + \".pth\")\r\n",
        "\r\n",
        "    #  ----------------------- VALIDATION -----------------------\r\n",
        "    \r\n",
        "    validation_pbar = tqdm(total=len(eval_data),\r\n",
        "                           position=0, leave=True,\r\n",
        "                           file=sys.stdout, bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % (Fore.BLUE, Fore.RESET))\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # Filter data\r\n",
        "    eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip is False]\r\n",
        "    currentIdx = 0\r\n",
        "    count = 0\r\n",
        "    val_loss = 0\r\n",
        "    \r\n",
        "    # Loop for every validation batch\r\n",
        "    for batch in validation_data_loader:\r\n",
        "\r\n",
        "      batch = tuple(t.to(gpu) for t in batch)\r\n",
        "      input_word_ids, input_mask, input_type_ids, start_token_idx, end_token_idx = batch\r\n",
        "\r\n",
        "      with torch.no_grad():\r\n",
        "\r\n",
        "          # predicted answer\r\n",
        "          start_logits, end_logits = model(input_ids=input_word_ids, attention_mask=input_mask, token_type_ids=input_type_ids, return_dict=False)\r\n",
        "\r\n",
        "          # prediction answer and end, detached (for memory usage and for summing them for acc)\r\n",
        "          pred_start, pred_end = start_logits.detach().cpu().numpy(), end_logits.detach().cpu().numpy()\r\n",
        "\r\n",
        "      # Evaluation based on Accuracy\r\n",
        "      for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\r\n",
        "        \r\n",
        "        squad_eg = eval_examples_no_skip[currentIdx]\r\n",
        "        currentIdx += 1\r\n",
        "        offsets = squad_eg.context_token_to_char\r\n",
        "\r\n",
        "        # Answer start and end\r\n",
        "        start = np.argmax(start)\r\n",
        "        end = np.argmax(end)\r\n",
        "        if start >= len(offsets):\r\n",
        "            continue\r\n",
        "\r\n",
        "        # Checking offsets\r\n",
        "        pred_char_start = offsets[start][0]\r\n",
        "        if end < len(offsets):\r\n",
        "            pred_char_end = offsets[end][1]\r\n",
        "            pred_ans = squad_eg.context[pred_char_start:pred_char_end]\r\n",
        "        else:\r\n",
        "            pred_ans = squad_eg.context[pred_char_start:]\r\n",
        "\r\n",
        "        # Normalizing text for comparison of predicted answer and true answer\r\n",
        "        normalized_pred_ans = normalize_text(pred_ans)\r\n",
        "\r\n",
        "        if squad_eg.all_answers!=None:\r\n",
        "          # all true answers to a list \r\n",
        "          normalized_true_ans = [normalize_text(x) for x in squad_eg.all_answers ]\r\n",
        "\r\n",
        "          # If predicted answer in true answers add +1 in Accuracy\r\n",
        "          if normalized_pred_ans in normalized_true_ans:\r\n",
        "              count += 1\r\n",
        "            \r\n",
        "        validation_pbar.update(input_word_ids.size(0))\r\n",
        "\r\n",
        "    # Final accuracy and loss\r\n",
        "    acc = count / len(y_eval[0])*100\r\n",
        "    validation_pbar.close()\r\n",
        "    print(\"Epoch \", str(epoch),\" | \",f\"Avg training loss: {training_loss:.4f}\",\" | \",f\"Validation accuracy: {acc:.2f} %\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m█████████▉\u001b[39m| 85008/85014 [1:57:54<00:00, 12.02it/s]\n",
            "|\u001b[34m          \u001b[39m| 98544/? [03:00<00:00, 546.68it/s]\n",
            "Epoch  1  |  Avg training loss: 1.9296  |  Validation accuracy: 72.29 %\n",
            "\n",
            "100%|\u001b[32m█████████▉\u001b[39m| 85008/85014 [1:57:50<00:00, 12.02it/s]\n",
            "|\u001b[34m          \u001b[39m| 98560/? [03:00<00:00, 546.98it/s]\n",
            "Epoch  2  |  Avg training loss: 1.3891  |  Validation accuracy: 74.12 %\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ov6DNTjukMW"
      },
      "source": [
        "# Testing\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD7K-vBWTC_P"
      },
      "source": [
        "## Evaluation fuction for test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psNwHJV64s1q"
      },
      "source": [
        "'''\r\n",
        "evaluation: Same method as validation but for testing purpose\r\n",
        "'''\r\n",
        "def evaluation(data):\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  test_samples = create_squad(data, \"Creating test points\",None)\r\n",
        "  x_test, _ = Xy_split(test_samples)\r\n",
        "\r\n",
        "  pred_start, pred_end = model(torch.tensor(x_test[0], dtype=torch.int64, device=gpu),\r\n",
        "                              torch.tensor(x_test[1], dtype=torch.float, device=gpu),\r\n",
        "                              torch.tensor(x_test[2], dtype=torch.int64, device=gpu), return_dict=False)\r\n",
        "\r\n",
        "  pred_start, pred_end = pred_start.detach().cpu().numpy(), pred_end.detach().cpu().numpy()\r\n",
        "\r\n",
        "  print(\"\\nQuestions and answers:\\n\")\r\n",
        "  for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\r\n",
        "      test_sample = test_samples[idx]\r\n",
        "      offsets = test_sample.context_token_to_char\r\n",
        "      start = np.argmax(start)\r\n",
        "      end = np.argmax(end)\r\n",
        "      pred_ans = None\r\n",
        "      if start >= len(offsets):\r\n",
        "          continue\r\n",
        "      pred_char_start = offsets[start][0]\r\n",
        "      if end < len(offsets):\r\n",
        "          pred_ans = test_sample.context[pred_char_start:offsets[end][1]]\r\n",
        "      else:\r\n",
        "          pred_ans = test_sample.context[pred_char_start:]\r\n",
        "\r\n",
        "      print(\"Question: \" + test_sample.question)\r\n",
        "      print(\"Answer:   \" + pred_ans,\"\\n\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udNVeuK3SyJ5"
      },
      "source": [
        "## Questions and paragraph for the apollo mission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZogBS0Nuozz"
      },
      "source": [
        "'''\r\n",
        "Information and questions for the Apollo program taken from Wikipedia\r\n",
        "'''\r\n",
        "apollo_data = {\"data\":\r\n",
        "    [\r\n",
        "        {\"title\": \"Project Apollo\",\r\n",
        "         \"paragraphs\": [\r\n",
        "             {\r\n",
        "                 \"context\": \"The Apollo program, also known as Project Apollo, was the third United States human \"\r\n",
        "                            \"spaceflight program carried out by the National Aeronautics and Space Administration (\"\r\n",
        "                            \"NASA), which accomplished landing the first humans on the Moon from 1969 to 1972. First \"\r\n",
        "                            \"conceived during Dwight D. Eisenhower's administration as a three-man spacecraft to \"\r\n",
        "                            \"follow the one-man Project Mercury which put the first Americans in space, Apollo was \"\r\n",
        "                            \"later dedicated to President John F. Kennedy's national goal of landing a man on the \"\r\n",
        "                            \"Moon and returning him safely to the Earth by the end of the 1960s, which he proposed in \"\r\n",
        "                            \"a May 25, 1961, address to Congress. Project Mercury was followed by the two-man Project \"\r\n",
        "                            \"Gemini. The first manned flight of Apollo was in 1968. Apollo ran from 1961 to 1972, \"\r\n",
        "                            \"and was supported by the two man Gemini program which ran concurrently with it from 1962 \"\r\n",
        "                            \"to 1966. Gemini missions developed some of the space travel techniques that were \"\r\n",
        "                            \"necessary for the success of the Apollo missions. Apollo used Saturn family rockets as \"\r\n",
        "                            \"in 1973-74, and the Apollo-Soyuz Test Project, a joint Earth orbit mission with the \"\r\n",
        "                            \"Soviet Union in 1975.\",\r\n",
        "                 \"qas\": [\r\n",
        "                     {\"question\": \"What project put the first Americans into space?\",\r\n",
        "                      \"id\": \"Q1\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      },\r\n",
        "                     {\"question\": \"What program was created to carry out these projects and missions?\",\r\n",
        "                      \"id\": \"Q2\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      },\r\n",
        "                     {\"question\": \"What year did the first manned Apollo flight occur?\",\r\n",
        "                      \"id\": \"Q3\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      },\r\n",
        "                     {\"question\": \"What President is credited with the original notion of putting Americans in space?\",\r\n",
        "                      \"id\": \"Q4\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      },\r\n",
        "                     {\"question\": \"Who did the U.S. collaborate with on an Earth orbit mission in 1975?\",\r\n",
        "                      \"id\": \"Q5\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      },\r\n",
        "                     {\"question\": \"How long did Project Apollo run?\",\r\n",
        "                      \"id\": \"Q6\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      },\r\n",
        "                     {\"question\": \"What program helped develop space travel techniques that Project Apollo used?\",\r\n",
        "                      \"id\": \"Q7\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      },\r\n",
        "                     {\"question\": \"What space station supported three manned missions in 1973-1974?\",\r\n",
        "                      \"id\": \"Q8\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      }\r\n",
        "                 ]\r\n",
        "              }\r\n",
        "            ]\r\n",
        "         }\r\n",
        "      ]\r\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4L1UzIQA1Vf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb5d783-ec1b-4e6e-cdb2-8a4a9f5bc716"
      },
      "source": [
        "evaluation(apollo_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating test points: 100%|\u001b[34m██████████\u001b[39m| 1/1 [00:00<00:00, 69.95it/s]\n",
            "\n",
            "Questions and answers:\n",
            "\n",
            "Question: What project put the first Americans into space?\n",
            "Answer:   Project Mercury \n",
            "\n",
            "Question: What program was created to carry out these projects and missions?\n",
            "Answer:    \n",
            "\n",
            "Question: What year did the first manned Apollo flight occur?\n",
            "Answer:   1968 \n",
            "\n",
            "Question: What President is credited with the original notion of putting Americans in space?\n",
            "Answer:   John F. Kennedy \n",
            "\n",
            "Question: Who did the U.S. collaborate with on an Earth orbit mission in 1975?\n",
            "Answer:   Soviet Union \n",
            "\n",
            "Question: How long did Project Apollo run?\n",
            "Answer:   1961 to 1972 \n",
            "\n",
            "Question: What program helped develop space travel techniques that Project Apollo used?\n",
            "Answer:   Gemini \n",
            "\n",
            "Question: What space station supported three manned missions in 1973-1974?\n",
            "Answer:   Saturn family rockets \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4bs-17OS7TB"
      },
      "source": [
        "## Questions and paragraphs about Beyonce"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4IxEvcLUAtJ"
      },
      "source": [
        "'''\r\n",
        "Information and questions for Beyonce taken from Wikipedia\r\n",
        "'''\r\n",
        "beyonce_data = {\"data\":\r\n",
        "    [\r\n",
        "        {\"title\": \"Beyonce\",\r\n",
        "         \"paragraphs\": [\r\n",
        "             {\r\n",
        "                  \"context\": \"Beyoncé Giselle Knowles-Carter is an American singer, songwriter, actress, and record producer.\"\r\n",
        "                            \"Born and raised in Houston, Texas, Beyoncé performed in various singing and dancing competitions as a child.\"\r\n",
        "                            \"During Destiny's Child's hiatus, Beyoncé made her theatrical film debut with \"\r\n",
        "                            \"a role in the US box-office number-one Austin Powers in Goldmember (2002) and began her solo music career.\"\r\n",
        "                            \"including the number-one singles 'Crazy in Love' featuring rapper Jay-Z and 'Baby Boy' featuring singer-rapper Sean Paul.\"\r\n",
        "                            \"Following the disbandment of Destiny's Child in 2006,\"\r\n",
        "                            \"she released her second solo album, B'Day, which contained her first \"\r\n",
        "                            \"US number-one solo single 'Irreplaceable', and 'Beautiful Liar', which topped the charts in most countries.\"\r\n",
        "                            \"Her marriage to Jay-Z and her portrayal of Etta James in Cadillac Records (2008) influenced her third album, \"\r\n",
        "                            \"I Am... Sasha Fierce (2008), which earned a record-setting six Grammy Awards in 2010.\",\r\n",
        "                 \"qas\": [\r\n",
        "                     {\"question\": \"Where was Beyoncé born?\",\r\n",
        "                      \"id\": \"Q1\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      },\r\n",
        "                     {\"question\": \"When Beyonce rose to fame?\",\r\n",
        "                      \"id\": \"Q2\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      },\r\n",
        "                     {\"question\": \"What year did Beyonce began her solo music career?\",\r\n",
        "                      \"id\": \"Q3\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      },\r\n",
        "                     {\"question\": \"Whats the name of the album that published in 2003?\",\r\n",
        "                      \"id\": \"Q4\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      },\r\n",
        "                     {\"question\": \"For which song did Beyonce won the Grammy Award?\",\r\n",
        "                      \"id\": \"Q5\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      },\r\n",
        "                     {\"question\": \"In which movies did she act?\",\r\n",
        "                      \"id\": \"Q6\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      },\r\n",
        "                     {\"question\": \"Who is Beyonces husband?\",\r\n",
        "                      \"id\": \"Q7\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      },\r\n",
        "                     {\"question\": \"Which was her first US number-one solo single?\",\r\n",
        "                      \"id\": \"Q8\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      },\r\n",
        "                     {\"question\": \"Was Beyonce a better magician than Harry Potter?\",\r\n",
        "                      \"id\": \"Q9\",\r\n",
        "                      \"is_impossible\": \"False\"\r\n",
        "                      }\r\n",
        "                 ]\r\n",
        "              }\r\n",
        "            ]\r\n",
        "         }\r\n",
        "     ]\r\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0EEdl_EA1di",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6955ff81-86a8-4bae-ae1b-476acdcea114"
      },
      "source": [
        "evaluation(beyonce_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating test points: 100%|\u001b[34m██████████\u001b[39m| 1/1 [00:00<00:00, 81.65it/s]\n",
            "\n",
            "Questions and answers:\n",
            "\n",
            "Question: Where was Beyoncé born?\n",
            "Answer:   Houston, Texas \n",
            "\n",
            "Question: When Beyonce rose to fame?\n",
            "Answer:   2002 \n",
            "\n",
            "Question: What year did Beyonce began her solo music career?\n",
            "Answer:   2002 \n",
            "\n",
            "Question: Whats the name of the album that published in 2003?\n",
            "Answer:   B'Day \n",
            "\n",
            "Question: For which song did Beyonce won the Grammy Award?\n",
            "Answer:   Sasha Fierce \n",
            "\n",
            "Question: In which movies did she act?\n",
            "Answer:   Austin Powers in Goldmember \n",
            "\n",
            "Question: Who is Beyonces husband?\n",
            "Answer:   Jay-Z \n",
            "\n",
            "Question: Which was her first US number-one solo single?\n",
            "Answer:   Irreplaceable \n",
            "\n",
            "Question: Was Beyonce a better magician than Harry Potter?\n",
            "Answer:   singer, songwriter, actress, and record producer \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPIuc_6nBO3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f0c52b-9714-4bbd-b19c-2d9c7c77de58"
      },
      "source": [
        "#@title Enter your question about __Beyonce__ { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Question = \"Where Beyonce was born?\" #@param {type:\"string\"}\n",
        "\n",
        "def qa(q):\n",
        "  model.eval()\n",
        "  data = {\"data\":\n",
        "    [\n",
        "        {\"title\": \"\",\n",
        "         \"paragraphs\": [\n",
        "             {\n",
        "                  \"context\": \"Beyoncé Giselle Knowles-Carter is an American singer, songwriter, actress, and record producer.\"\n",
        "                            \"Born and raised in Houston, Texas, Beyoncé performed in various singing and dancing competitions as a child.\"\n",
        "                            \"During Destiny's Child's hiatus, Beyoncé made her theatrical film debut with \"\n",
        "                            \"a role in the US box-office number-one Austin Powers in Goldmember (2002) and began her solo music career.\"\n",
        "                            \"including the number-one singles 'Crazy in Love' featuring rapper Jay-Z and 'Baby Boy' featuring singer-rapper Sean Paul.\"\n",
        "                            \"Following the disbandment of Destiny's Child in 2006,\"\n",
        "                            \"she released her second solo album, B'Day, which contained her first \"\n",
        "                            \"US number-one solo single 'Irreplaceable', and 'Beautiful Liar', which topped the charts in most countries.\"\n",
        "                            \"Her marriage to Jay-Z and her portrayal of Etta James in Cadillac Records (2008) influenced her third album, \"\n",
        "                            \"I Am... Sasha Fierce (2008), which earned a record-setting six Grammy Awards in 2010.\",\n",
        "                   \"qas\": [\n",
        "                     {\"question\": q,\n",
        "                      \"id\": \"Q1\",\n",
        "                      \"is_impossible\": \"False\"\n",
        "                      },\n",
        "              ]\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "    ]\n",
        "  }\n",
        "  test_samples = create_squad(data, \"\",None)\n",
        "  x_test, _ = Xy_split(test_samples)\n",
        "\n",
        "  pred_start, pred_end = model(torch.tensor(x_test[0], dtype=torch.int64, device=gpu),\n",
        "                              torch.tensor(x_test[1], dtype=torch.float, device=gpu),\n",
        "                              torch.tensor(x_test[2], dtype=torch.int64, device=gpu), return_dict=False)\n",
        "\n",
        "  pred_start, pred_end = pred_start.detach().cpu().numpy(), pred_end.detach().cpu().numpy()\n",
        "\n",
        "  for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "      test_sample = test_samples[idx]\n",
        "      offsets = test_sample.context_token_to_char\n",
        "      start = np.argmax(start)\n",
        "      end = np.argmax(end)\n",
        "      pred_ans = None\n",
        "      if start >= len(offsets):\n",
        "          continue\n",
        "      pred_char_start = offsets[start][0]\n",
        "      if end < len(offsets):\n",
        "          pred_ans = test_sample.context[pred_char_start:offsets[end][1]]\n",
        "      else:\n",
        "          pred_ans = test_sample.context[pred_char_start:]\n",
        "\n",
        "      print(Fore.RED +\"\\nAnswer: \" + Fore.GREEN + pred_ans,\"\\n\")  \n",
        "qa(Question)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m\n",
            "Answer: \u001b[32mHouston, Texas \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu-uaHlGev8X"
      },
      "source": [
        "# Remarks\r\n",
        "---\r\n",
        "\r\n",
        "## __Summary__\r\n",
        "\r\n",
        "In this notebook I have implemented:\r\n",
        "- A parser for SQuAD 2.0 dataset\r\n",
        "- Transformer for the data into tensors\r\n",
        "- Training method for BERT in combination with SQuAD\r\n",
        "- Evaluated based on validation set\r\n",
        "\r\n",
        "## __Fine tunning__\r\n",
        "\r\n",
        "- Tested the training model for multiple number of epochs (1,2,3,4)\r\n",
        "- batch sizes (I faced multiple problems in memory allocation for big batches and for this reason I am using 16 that in undoubtly small)\r\n",
        "- Optimizer (Adam) in:\r\n",
        "  - ```lr``` (float, optional) – learning rate (default: 1e-3)\r\n",
        "  - ```betas``` (Tuple[float, float], optional) – coefficients used for computing    running averages of gradient and its square (default: (0.9, 0.999))\r\n",
        "  - ```eps``` (float, optional) – term added to the denominator to improve numerical stability (default: 1e-8)\r\n",
        "\r\n",
        "I concluded to the parameters I used as these were the best. I had some good results in the answers that the model gave as most of them answered my questions both for Apollo and Beyonce.\r\n",
        "\r\n",
        "## __Accuracy__\r\n",
        "Epochs made a real difference in the validation accuracy. Approximately this model has a 74% accuracy that is not bad, if we consider the oficial SQuAD results. \r\n",
        "\r\n",
        "*Didn't understand how F1 score should be measured as it consists of Recall and Presicion and I didn't found a good way to measure them in my implementation.\r\n",
        "\r\n",
        "## __Time needed to execute__\r\n",
        "At least 2 hours in colabs cuda for each epoch\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGlvItYLrQri"
      },
      "source": [
        "# References\r\n",
        "---\r\n",
        "\r\n",
        "[1]  [Fine tunning in SQuAD 1.1 ](https://github.com/dredwardhyde/bert-examples/blob/main/bert_squad_pytorch.py)"
      ]
    }
  ]
}